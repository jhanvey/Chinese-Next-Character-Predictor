{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8947357c",
   "metadata": {
    "id": "8947357c"
   },
   "source": [
    "# Chinese Next Character Predictor\n",
    "### *Bigram model with unicode backoff*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3127d7",
   "metadata": {
    "id": "cd3127d7"
   },
   "source": [
    "### Overview\n",
    "\n",
    "There are over 50,000 individual characters (though the average person fluent in Chinese uses far fewer characters). Many of these characters when Romanized using Hanyu Pinyin have similar phonetic spelling.\n",
    "\n",
    "This project uses a bigram model (with unigram backoff) to predict the correct Chinese character when given the Hanyu Pinyin phonetic spelling for each character.\n",
    "\n",
    "*Please Note: This project has been modified from a project for the course DTSC 685 Natural Language Processing at Eastern University. The datasets used were supplied by the professor. As a challenge for this project, we were only allowed to use base Python and the 'Collections' library.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b824b",
   "metadata": {
    "id": "e52b824b"
   },
   "source": [
    "## Chinese Data Setup\n",
    "\n",
    "There are six files for this project:\n",
    "- `chinese/train.han`: A training file using Chinese characters.\n",
    "- `chinese/charmap`: A character map. Each line in this file contains exactly two whitespace-seperated columns. The first column is a Chinese character and the second column is the pronunciation.\n",
    "- `chinese/dev.pin`: A file of inputs for the dev set using phonetic\n",
    "- `chinese/test.pin`: A file of inputs for the test set. For each whitespace-seperated token in this file, you will predict which character the user meant to type.\n",
    "- `chinese/dev.han`: A file of correct outputs for the dev set. You will compare your predictions on the dev set to this file.\n",
    "- `chinese/test.han`: A file of correct outputs for the test set. You will compare your predictions on the test set to this file.\n",
    "\n",
    "The following paths to the Chinese text data are stored for convenience. Create a list of characters called `chinese_chars` that contains every Chinese character in the charmap file as well as a list of tuples called `prons` that contains the typed pronunciations as the first entry in the tuple and the associated Chinese character as the second entry in the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "898045d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1709605809581,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "898045d3",
    "outputId": "94ce7822-32f3-417b-ac2a-8ee778ba060a"
   },
   "outputs": [],
   "source": [
    "# Loading the 'Collections' library\n",
    "import collections\n",
    "\n",
    "# Mapping the data paths\n",
    "\n",
    "charmap = './data/charmap'\n",
    "chinese_dev_pin = './data/dev.pin'\n",
    "chinese_dev_han = './data/dev.han'\n",
    "chinese_test_pin = './data/test.pin'\n",
    "chinese_test_han = './data/test.han'\n",
    "chinese_train = './data/train.han'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "RCeQAb478Z0_",
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1709605809773,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "RCeQAb478Z0_"
   },
   "outputs": [],
   "source": [
    "# Reading and mapping the pronounciations\n",
    "\n",
    "charmap_list = list(open(charmap, 'r', encoding='utf-8'))\n",
    "chinese_chars = []\n",
    "pronunciation = []\n",
    "\n",
    "for i in charmap_list:\n",
    "    x = i.split()\n",
    "    chinese_chars.append(x[0])\n",
    "    pronunciation.append(x[1])\n",
    "\n",
    "pronunciations = list(zip(pronunciation, chinese_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qBl_YMfj9cY-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1709605809774,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "qBl_YMfj9cY-",
    "outputId": "4ac73637-8948-4d6b-f4e6-89d194128835"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('qiu', '㐀'),\n",
       " ('tian', '㐁'),\n",
       " ('kua', '㐄'),\n",
       " ('wu', '㐅'),\n",
       " ('yin', '㐆'),\n",
       " ('yi', '㐌'),\n",
       " ('xie', '㐖'),\n",
       " ('chou', '㐜'),\n",
       " ('nuo', '㐡'),\n",
       " ('dan', '㐤'),\n",
       " ('xu', '㐨'),\n",
       " ('xing', '㐩'),\n",
       " ('xiong', '㐫'),\n",
       " ('liu', '㐬'),\n",
       " ('lin', '㐭'),\n",
       " ('xiang', '㐮'),\n",
       " ('yong', '㐯'),\n",
       " ('xin', '㐰'),\n",
       " ('zhen', '㐱'),\n",
       " ('dai', '㐲'),\n",
       " ('wu', '㐳'),\n",
       " ('pan', '㐴'),\n",
       " ('ru', '㐵'),\n",
       " ('ma', '㐷'),\n",
       " ('qian', '㐸'),\n",
       " ('yi', '㐹'),\n",
       " ('yin', '㐺'),\n",
       " ('nei', '㐻'),\n",
       " ('cheng', '㐼'),\n",
       " ('feng', '㐽'),\n",
       " ('zhuo', '㑁'),\n",
       " ('fang', '㑂'),\n",
       " ('ao', '㑃'),\n",
       " ('wu', '㑄'),\n",
       " ('zuo', '㑅'),\n",
       " ('zhou', '㑇'),\n",
       " ('dong', '㑈'),\n",
       " ('su', '㑉'),\n",
       " ('yi', '㑊'),\n",
       " ('qiong', '㑋'),\n",
       " ('kuang', '㑌'),\n",
       " ('lei', '㑍'),\n",
       " ('nao', '㑎'),\n",
       " ('zhu', '㑏'),\n",
       " ('shu', '㑐'),\n",
       " ('xu', '㑔'),\n",
       " ('shen', '㑗'),\n",
       " ('jie', '㑘'),\n",
       " ('die', '㑙'),\n",
       " ('nuo', '㑚')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing the first 50 pronunciations\n",
    "pronunciations[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9ab28",
   "metadata": {
    "id": "35a9ab28"
   },
   "source": [
    "## Chinese Character Candidate\n",
    "\n",
    "The Candidates function takes an input token as a parameter and returns a list of possible characters that the token could specify. Each input token could be one of the following:\n",
    "- a typed pronunciation, which can convert to one of the Chinese characters from the charmap,\n",
    "- an English character, which can convert to itself\n",
    "- `<space>`, which converts to a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451521ed",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709605809774,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "451521ed"
   },
   "outputs": [],
   "source": [
    "def Candidates(token):\n",
    "    candidates = []\n",
    "\n",
    "    # If pronunciation\n",
    "    found = 0\n",
    "    for pair in pronunciations:\n",
    "        if pair[0] == token:\n",
    "            candidates.append(pair[1])\n",
    "            found = 1\n",
    "\n",
    "    # If space\n",
    "    if token == '<space>':\n",
    "        candidates.append(' ')\n",
    "\n",
    "    # If English character\n",
    "    if len(token) == 1:\n",
    "        candidates.append(token)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DaFfaletUftj",
   "metadata": {
    "id": "DaFfaletUftj"
   },
   "source": [
    "## Bigram Character Predictor (Without Unigram Backoff)\n",
    "\n",
    "Below is a bigram class and bigram next character predictor (without unigram backoff) that takes in previous predicted Chinese character and the current Pinyin pronounciation and makes a prediction of what Chinese character it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d013e19f",
   "metadata": {
    "id": "d013e19f"
   },
   "source": [
    "### Bigram Class\n",
    "\n",
    "*Original Instructor Instructions: Create a Bigram class, which modifies the Unigram class [from an earlier assignment] to implement a bigram language model. It should contain the same methods as the Unigram class, which should be modified (and in some cases defined) for bigrams. You do not need to modify the `__init()__` method.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a72155f",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709605809775,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "5a72155f"
   },
   "outputs": [],
   "source": [
    "class Bigram(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counts = collections.Counter()\n",
    "        self.total_count = 0\n",
    "        self.current = []\n",
    "\n",
    "    def train(self, filename):\n",
    "        # Trains the model on a text file\n",
    "        for line in open(filename, encoding='utf-8'):\n",
    "            line = '^' + '^' + line\n",
    "            self.start()\n",
    "            for w in line.rstrip('\\n'):\n",
    "                self.read(w)\n",
    "                gram = \"\".join(self.current)\n",
    "                self.counts[gram] += 1\n",
    "                self.total_count += 1\n",
    "\n",
    "    def start(self):\n",
    "        # Resets the state to the initial state\n",
    "        self.current = ['^', '^']\n",
    "\n",
    "    def read(self, w):\n",
    "        # Reads in w, updating the state\n",
    "        self.current.pop(0)\n",
    "        self.current.append(w)\n",
    "\n",
    "    def prob(self, w):\n",
    "        # Returns the probability of the next character being w given the current state\n",
    "        temp = self.current[1:2]\n",
    "        temp.append(w)\n",
    "        guess = \"\".join(temp)\n",
    "\n",
    "        return self.counts[guess] / self.total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73673646",
   "metadata": {
    "id": "73673646"
   },
   "source": [
    "### Bigram Character Predictor Function\n",
    "\n",
    "*Original Instructor Instructions: Create a Bigram Character Prediction function. This function should create an object of the Bigram class and train it on a training file. It should then predict the most probable Chinese character for each token in a test file from the list of candidate characters generated by `Candidate(token)`. The Bigram Character Prediction function should also calculate the total number of correct predictions it makes for the test file and return the percentage of correct predictions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2999714",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1709605809775,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "f2999714"
   },
   "outputs": [],
   "source": [
    "def BigramCharPred(train_file, test_file, correct_output):\n",
    "    bigram = Bigram()\n",
    "    bigram.train(train_file)\n",
    "\n",
    "    test_list = list(open(test_file, 'r', encoding='utf-8'))\n",
    "    correct_list = list(open(correct_output, 'r', encoding='utf-8'))\n",
    "    correct_list_chars = []\n",
    "\n",
    "    for line in correct_list:\n",
    "        line = line[:-1]\n",
    "        for char in line:\n",
    "            correct_list_chars.append(char)\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "\n",
    "    bigram.start()\n",
    "\n",
    "    for line in test_list:\n",
    "        tokens = line.split()\n",
    "        for token in tokens:\n",
    "            candidates = Candidates(token)\n",
    "\n",
    "            char_probs = []\n",
    "            for char in candidates:\n",
    "                char_probs.append(bigram.prob(char))\n",
    "\n",
    "\n",
    "            index = char_probs.index(max(char_probs))\n",
    "            most_likely = candidates[index]\n",
    "\n",
    "            prediction.append(most_likely)\n",
    "            bigram.read(most_likely)\n",
    "\n",
    "    correct = 0\n",
    "    total_tested = 0\n",
    "\n",
    "    for n in range(len(correct_list_chars)):\n",
    "        if prediction[n] == correct_list_chars[n]:\n",
    "            correct += 1\n",
    "            total_tested += 1\n",
    "        else:\n",
    "            total_tested +=1\n",
    "\n",
    "\n",
    "    return correct/total_tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "NyTnejMKXO8K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8872,
     "status": "ok",
     "timestamp": 1709605818635,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "NyTnejMKXO8K",
    "outputId": "45cc75aa-1605-406a-e8dc-b21996100aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese character prediction bigram accuracy on dev set: 0.7785547785547785\n"
     ]
    }
   ],
   "source": [
    "bigram_dev_accuracy = BigramCharPred(chinese_train, chinese_dev_pin, chinese_dev_han)\n",
    "print('Chinese character prediction bigram accuracy on dev set: '+ str(bigram_dev_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "UQNkvK-dXoL9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4495,
     "status": "ok",
     "timestamp": 1709605823099,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "UQNkvK-dXoL9",
    "outputId": "c1ff0260-a6da-453a-d190-0f9c1f3ec8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese character prediction bigram accuracy on test set: 0.5886157826649417\n"
     ]
    }
   ],
   "source": [
    "bigram_test_accuracy = BigramCharPred(chinese_train, chinese_test_pin, chinese_test_han)\n",
    "print('Chinese character prediction bigram accuracy on test set: '+ str(bigram_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8778c40",
   "metadata": {
    "id": "c8778c40"
   },
   "source": [
    "## Bigram Character Predictor With Backoff\n",
    "\n",
    "We can improve our bigram model by adding unigram backoff for instances where we do not have bigram data.\n",
    "\n",
    "Below is a unigram class needed for backoff and the bigram next character predictor with unigram backoff that takes in previous predicted Chinese character and the current Pinyin pronounciation and makes a prediction of what Chinese character it is.\n",
    "\n",
    "When we add unigram backoff, our model improves from 59% accuracy to 81% accuracy on the test data. This is a huge improvement!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07033620",
   "metadata": {
    "id": "07033620"
   },
   "source": [
    "### Unigram Class\n",
    "\n",
    "This unigram class we created on an earlier assignment in DTSC 685. We need it for the unigram backoff to improve our next character predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c10d154",
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1709605823099,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "3c10d154"
   },
   "outputs": [],
   "source": [
    "class Unigram(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.counts = collections.Counter()\n",
    "        self.total_count = 0\n",
    "\n",
    "    def train(self, filename):\n",
    "        #Trains the model on a text file\n",
    "        for line in open(filename, encoding='utf-8'):\n",
    "            for w in line.rstrip('\\n'):\n",
    "                self.counts[w] += 1\n",
    "                self.total_count += 1\n",
    "\n",
    "    def prob(self, w):\n",
    "        # Return the probability of the next character being w given the current state\n",
    "        return self.counts[w] / self.total_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kU-j_E6RZQoJ",
   "metadata": {
    "id": "kU-j_E6RZQoJ"
   },
   "source": [
    "### Bigram Character Predictor With Backoff Function\n",
    "\n",
    "\n",
    "*Original Instructor Instructions: Create another Bigram Character Prediction function. This function should work the same as your first Bigram Character prediction function, but this time it should use backoff. If the bigram returns a probability of 0 for all candidate characters, use the unigram to predict the character.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pzOwhLYA6fFD",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1709605823099,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "pzOwhLYA6fFD"
   },
   "outputs": [],
   "source": [
    "def BackoffCharPred(train_file, test_file, correct_output):\n",
    "\n",
    "    # Unigram\n",
    "    unigram = Unigram()\n",
    "    unigram.train(train_file)\n",
    "\n",
    "    # Bigram\n",
    "    bigram = Bigram()\n",
    "    bigram.train(train_file)\n",
    "\n",
    "    test_list = list(open(test_file, 'r', encoding='utf-8'))\n",
    "    correct_list = list(open(correct_output, 'r', encoding='utf-8'))\n",
    "    correct_list_chars = []\n",
    "\n",
    "    for line in correct_list:\n",
    "        line = line[:-1]\n",
    "        for char in line:\n",
    "            correct_list_chars.append(char)\n",
    "\n",
    "    prediction = []\n",
    "    char_num = -1\n",
    "\n",
    "\n",
    "    for line in test_list:\n",
    "        bigram.start()\n",
    "        tokens = line.split()\n",
    "        for token in tokens:\n",
    "            candidates = Candidates(token)\n",
    "\n",
    "            char_probs = []\n",
    "            for char in candidates:\n",
    "                char_probs.append(bigram.prob(char))\n",
    "\n",
    "            # Bigram Selection\n",
    "            if max(char_probs) > 0:\n",
    "                index = char_probs.index(max(char_probs))\n",
    "                most_likely = candidates[index]\n",
    "\n",
    "                prediction.append(most_likely)\n",
    "                char_num += 1\n",
    "                bigram.read(prediction[char_num])\n",
    "\n",
    "            # Unigram Backoff\n",
    "            else:\n",
    "                char_probs = []\n",
    "                for char in candidates:\n",
    "                    char_probs.append(unigram.prob(char))\n",
    "\n",
    "                index = char_probs.index(max(char_probs))\n",
    "\n",
    "                unigram_answer = candidates[index]\n",
    "\n",
    "                prediction.append(unigram_answer)\n",
    "                char_num += 1\n",
    "                bigram.read(prediction[char_num])\n",
    "\n",
    "    correct = 0\n",
    "    total_tested = 0\n",
    "\n",
    "    for n in range(len(correct_list_chars)):\n",
    "        if prediction[n] == correct_list_chars[n]:\n",
    "            correct += 1\n",
    "            total_tested += 1\n",
    "        else:\n",
    "            total_tested += 1\n",
    "\n",
    "    return correct/total_tested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7305ca0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7199,
     "status": "ok",
     "timestamp": 1709605830269,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "7305ca0a",
    "outputId": "8aac4464-9ea7-46c3-9b67-51e0b0df9694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese character prediction (Bigram with backoff) accuracy on dev set: 0.8863636363636364\n"
     ]
    }
   ],
   "source": [
    "backoff_dev_accuracy = BackoffCharPred(chinese_train, chinese_dev_pin, chinese_dev_han)\n",
    "print('Chinese character prediction (Bigram with backoff) accuracy on dev set: '+ str(backoff_dev_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "960da9b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5506,
     "status": "ok",
     "timestamp": 1709605835712,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "960da9b6",
    "outputId": "4a41c333-b282-47cc-cc19-a8a7d1adaae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese character prediction (Bigram with backoff) accuracy on test set: 0.8163001293661061\n"
     ]
    }
   ],
   "source": [
    "backoff_test_accuracy = BackoffCharPred(chinese_train, chinese_test_pin, chinese_test_han)\n",
    "print('Chinese character prediction (Bigram with backoff) accuracy on test set: '+ str(backoff_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jA9Y4DzX4LH5",
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1709605835713,
     "user": {
      "displayName": "Jesse Hanvey",
      "userId": "00581011142096544924"
     },
     "user_tz": 360
    },
    "id": "jA9Y4DzX4LH5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
